import pandas as pd
import numpy as np

# åŠ è½½æ•°æ®é›†
df = pd.read_csv('accepted_filtered_clean.csv')
# éªŒè¯å…³é”®å­—æ®µ
required_cols = ['label', 'UnRate', 'issue_d']
missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    raise ValueError(f"æ•°æ®é›†ç¼ºå¤±å…³é”®å­—æ®µï¼š{missing_cols}ï¼Œè¯·è¡¥å……æˆ–è°ƒæ•´å­—æ®µåï¼")
print("âœ… label/UnRate/issue_dï¼‰å‡å­˜åœ¨")

# 1. è½¬æ¢æ—¶é—´å­—æ®µï¼ˆå‡è®¾æ ¼å¼ä¸º"2018-01"ï¼Œè‹¥ä¸åŒéœ€è°ƒæ•´formatå‚æ•°ï¼‰
df['issue_d'] = pd.to_datetime(df['issue_d'], format='%Y-%m')
df['issue_year'] = df['issue_d'].dt.year

# 2. å®šä¹‰åœºæ™¯ï¼ˆäºŒé€‰ä¸€ï¼Œæ¨èæ–¹å¼1ï¼Œæ›´è´´åˆå®è§‚äº‹ä»¶ï¼‰
# æ–¹å¼1ï¼šæŒ‰æ—¶é—´åˆ’åˆ†ï¼ˆä¾‹ï¼š2020-2021å¹´ç–«æƒ…ä¸ºå†²å‡»æœŸï¼‰
shock_mask = df['issue_year'].between(2008, 2009)
# æ–¹å¼2ï¼šæŒ‰å¤±ä¸šç‡åˆ’åˆ†ï¼ˆUnRate>å†å²å‡å€¼1.2å€ä¸ºå†²å‡»æœŸï¼Œé€‚é…æ— æ˜ç¡®äº‹ä»¶åœºæ™¯ï¼‰
# unrate_mean = df['UnRate'].mean()
# shock_mask = df['UnRate'] > unrate_mean * 1.2

# æ‹†åˆ†æ ·æœ¬
shock_df = df[shock_mask].copy()  # å†²å‡»æœŸæ ·æœ¬
normal_df = df[~shock_mask].copy()  # æ­£å¸¸æœŸæ ·æœ¬

# éªŒè¯æ ‡ç­¾æ ¼å¼ï¼ˆç¡®ä¿ä¸º0=æ­£å¸¸ï¼Œ1=è¿çº¦ï¼‰
df['label'] = df['label'].astype(int)
shock_df['label'] = shock_df['label'].astype(int)
normal_df['label'] = normal_df['label'].astype(int)

# è¾“å‡ºæ ·æœ¬æ¦‚å†µ
print(f"ğŸ“Š å†²å‡»æœŸæ ·æœ¬ï¼š{shock_df.shape[0]}æ¡ï¼Œè¿çº¦ç‡ï¼š{shock_df['label'].mean():.3f}")
print(f"ğŸ“Š æ­£å¸¸æœŸæ ·æœ¬ï¼š{normal_df.shape[0]}æ¡ï¼Œè¿çº¦ç‡ï¼š{normal_df['label'].mean():.3f}")

def clean_dataset(data):
    # 1. åˆ é™¤æ ‡ç­¾ç¼ºå¤±çš„æ ·æœ¬
    data = data.dropna(subset=['label'])
    # 2. æ•°å€¼å‹ç‰¹å¾ï¼ˆå«UnRateï¼‰ç”¨ä¸­ä½æ•°å¡«å……ï¼ˆæŠ—æç«¯å€¼ï¼‰
    num_cols = data.select_dtypes(include=['int64', 'float64']).columns.drop('label')
    for col in num_cols:
        data[col] = data[col].fillna(data[col].median())
    # 3. åˆ†ç±»å‹ç‰¹å¾ç”¨ä¼—æ•°å¡«å……ï¼ˆè‹¥æ•°æ®å«åˆ†ç±»å‹å­—æ®µï¼Œå¦‚loan_statusï¼‰
    cat_cols = data.select_dtypes(include=['object']).columns
    for col in cat_cols:
        data[col] = data[col].fillna(data[col].mode()[0])
        # ç¼–ç åˆ†ç±»å‹ç‰¹å¾ï¼ˆè½¬ä¸ºæ•°å€¼ï¼‰
        data[col] = data[col].astype('category').cat.codes
    return data

# æ¸…æ´—ä¸¤ç»„æ ·æœ¬
shock_df_clean = clean_dataset(shock_df)
normal_df_clean = clean_dataset(normal_df)
print("âœ… æ•°æ®æ¸…æ´—å®Œæˆï¼ˆç¼ºå¤±å€¼å¤„ç†+åˆ†ç±»å‹ç¼–ç ï¼‰")

def split_features(data):
    # 1. åŸºç¡€ç‰¹å¾ï¼šå¸¸è§„é£æ§ç‰¹å¾ï¼ˆæ’é™¤æ ‡ç­¾ã€æ—¶é—´ã€å®è§‚å˜é‡ï¼‰
    basic_features = [
        'annual_inc',  # å€Ÿæ¬¾äººå¹´æ”¶å…¥
        'loan_amnt',   # è´·æ¬¾é‡‘é¢
        'dti',         # å€ºåŠ¡æ”¶å…¥æ¯”
        'fico_range_low',  # ä¿¡ç”¨è¯„åˆ†ä¸‹é™
        'term',        # è´·æ¬¾æœŸé™ï¼ˆå·²ç¼–ç ï¼‰
        'emp_length'   # å°±ä¸šæ—¶é•¿ï¼ˆå·²ç¼–ç ï¼‰
    ]
    # è¿‡æ»¤æ•°æ®ä¸­ä¸å­˜åœ¨çš„åŸºç¡€ç‰¹å¾ï¼ˆé¿å…æŠ¥é”™ï¼‰
    basic_features = [col for col in basic_features if col in data.columns]

    # 2. å®è§‚å˜é‡ï¼šä»¥UnRateä¸ºæ ¸å¿ƒï¼ˆå¯è¡¥å……å…¶ä»–å®è§‚æŒ‡æ ‡ï¼Œå¦‚CPIï¼Œè‹¥æ•°æ®æœ‰ï¼‰
    macro_features = ['UnRate']  # æ ¸å¿ƒå®è§‚å˜é‡ï¼šå¤±ä¸šç‡
    macro_features = [col for col in macro_features if col in data.columns]

    # 3. ä¸¤ç§ç‰¹å¾ç»„åˆï¼ˆå…³é”®å¯¹æ¯”ç»„ï¼‰
    features_no_macro = basic_features  # æœªèåˆå®è§‚å˜é‡ï¼ˆä»…åŸºç¡€ç‰¹å¾ï¼‰
    features_with_macro = basic_features + macro_features  # èåˆå®è§‚å˜é‡ï¼ˆåŸºç¡€+UnRateï¼‰

    # è¾“å‡ºç‰¹å¾æ¦‚å†µ
    print(f"\nğŸ” åŸºç¡€ç‰¹å¾ï¼ˆå…±{len(basic_features)}ä¸ªï¼‰ï¼š{basic_features}")
    print(f"ğŸ” å®è§‚å˜é‡ï¼ˆå…±{len(macro_features)}ä¸ªï¼‰ï¼š{macro_features}")
    print(f"ğŸ” èåˆåç‰¹å¾ï¼ˆå…±{len(features_with_macro)}ä¸ªï¼‰ï¼š{features_with_macro}")
    return features_no_macro, features_with_macro

# åˆ’åˆ†ç‰¹å¾ï¼ˆç”¨æ­£å¸¸æœŸæ•°æ®ç¡®è®¤å­—æ®µï¼Œä¸¤ç»„æ ·æœ¬ç‰¹å¾ä¸€è‡´ï¼‰
features_no_macro, features_with_macro = split_features(normal_df_clean)

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
# è®­ç»ƒå‰å‡†å¤‡ï¼ˆæ ·æœ¬æ‹†åˆ† + å¹³è¡¡ï¼‰
def prepare_train_data(data, features):
    # æå–ç‰¹å¾å’Œæ ‡ç­¾
    X = data[features]
    y = data['label']
    # 7:3æ‹†åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼ˆåˆ†å±‚æŠ½æ ·ï¼Œä¿è¯è¿çº¦ç‡ä¸€è‡´ï¼‰
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    # SMOTEè¿‡é‡‡æ ·ï¼ˆä»…è®­ç»ƒé›†ï¼Œé¿å…æ•°æ®æ³„éœ²ï¼‰
    smote = SMOTE(random_state=42)
    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
    # æ ‡å‡†åŒ–ï¼ˆä»…å¯¹é€»è¾‘å›å½’ï¼ŒXGBoostæ— éœ€æ ‡å‡†åŒ–ï¼‰
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_smote)
    X_test_scaled = scaler.transform(X_test)
    return (X_train_scaled, X_test_scaled, y_train_smote, y_test), scaler

# æ¨¡å‹è®­ç»ƒä¸è¶…å‚æ•°è°ƒä¼˜
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score, confusion_matrix

def train_optimized_model(model_type, X_train, y_train):
    # å®šä¹‰æ¨¡å‹ä¸è¶…å‚æ•°ç½‘æ ¼
    if model_type == 'lr':  # é€»è¾‘å›å½’
        model = LogisticRegression(random_state=42, max_iter=1000)
        param_grid = {'C': [0.01, 0.1, 1, 10]}  # æ­£åˆ™åŒ–ç³»æ•°ï¼ˆæ§åˆ¶è¿‡æ‹Ÿåˆï¼‰
    elif model_type == 'xgb':  # XGBoost
        model = XGBClassifier(random_state=42, objective='binary:logistic', eval_metric='auc')
        param_grid = {
            'learning_rate': [0.01, 0.1],  # æ­¥é•¿
            'max_depth': [3, 5],  # æ ‘æ·±åº¦ï¼ˆæ§åˆ¶è¿‡æ‹Ÿåˆï¼‰
            'n_estimators': [100, 200]  # æ ‘æ•°é‡
        }
    else:
        raise ValueError("æ¨¡å‹ç±»å‹ä»…æ”¯æŒ'lr'ï¼ˆé€»è¾‘å›å½’ï¼‰å’Œ'xgb'ï¼ˆXGBoostï¼‰")

    # ç½‘æ ¼æœç´¢è°ƒä¼˜ï¼ˆ5æŠ˜äº¤å‰éªŒè¯ï¼Œä»¥AUCä¸ºç›®æ ‡ï¼‰
    grid_search = GridSearchCV(
        model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=0
    )
    grid_search.fit(X_train, y_train)
    return grid_search.best_estimator_  # è¿”å›æœ€ä¼˜æ¨¡å‹

# å­˜å‚¨æ‰€æœ‰æ¨¡å‹ç»“æœï¼ˆkeyï¼šåœºæ™¯_æ¨¡å‹_ç‰¹å¾ç»„åˆï¼Œvalueï¼šAUCã€è¿çº¦å‡†ç¡®ç‡ç­‰ï¼‰
model_results = {}

# éå†æ‰€æœ‰åœºæ™¯ã€æ¨¡å‹ç±»å‹ã€ç‰¹å¾ç»„åˆï¼ˆå…±2åœºæ™¯Ã—2æ¨¡å‹Ã—2ç‰¹å¾=8ç»„ç»“æœï¼‰
scenes = [('æ­£å¸¸æœŸ', normal_df_clean), ('å†²å‡»æœŸ', shock_df_clean)]
model_types = ['lr', 'xgb']
feature_groups = [
    ('æœªèåˆå®è§‚', features_no_macro),
    ('èåˆå®è§‚(å«UnRate)', features_with_macro)
]

#
for scene_name, scene_data in scenes:
    for model_type in model_types:
        for feat_name, features in feature_groups:
            # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
            (X_train, X_test, y_train, y_test), _ = prepare_train_data(scene_data, features)
            # 2. è®­ç»ƒä¼˜åŒ–æ¨¡å‹
            best_model = train_optimized_model(model_type, X_train, y_train)
            # 3. é¢„æµ‹ä¸è¯„ä¼°
            y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # è¿çº¦æ¦‚ç‡
            y_pred = best_model.predict(X_test)  # ç±»åˆ«é¢„æµ‹
            # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
            auc = roc_auc_score(y_test, y_pred_proba)
            tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
            default_acc = tp / (tp + fn) if (tp + fn) > 0 else 0  # è¿çº¦é¢„æµ‹å‡†ç¡®ç‡
            # å­˜å‚¨ç»“æœ
            result_key = f"{scene_name}_{model_type.upper()}_{feat_name}"
            model_results[result_key] = {
                'AUC': round(auc, 4),
                'è¿çº¦é¢„æµ‹å‡†ç¡®ç‡': round(default_acc, 4),
                'æ¨¡å‹': best_model
            }
            # è¾“å‡ºè®­ç»ƒç»“æœ
            print(f"âœ… {result_key}ï¼šAUC={auc:.4f}ï¼Œè¿çº¦å‡†ç¡®ç‡={default_acc:.4f}")
            
import pandas as pd

# 1. æ•´ç†æ¨¡å‹ç»“æœä¸ºDataFrame
result_list = []
for key, metrics in model_results.items():
    scene, model, feat_type = key.split('_', 2)  # æ‹†åˆ†åœºæ™¯ã€æ¨¡å‹ã€ç‰¹å¾ç±»å‹
    result_list.append({
        'åœºæ™¯': scene,
        'æ¨¡å‹ç±»å‹': model,
        'ç‰¹å¾ç»„åˆ': feat_type,
        'AUC': metrics['AUC'],
        'è¿çº¦é¢„æµ‹å‡†ç¡®ç‡': metrics['è¿çº¦é¢„æµ‹å‡†ç¡®ç‡']
    })
result_df = pd.DataFrame(result_list)
print("\nğŸ“‹ æ‰€æœ‰æ¨¡å‹æ ¸å¿ƒæŒ‡æ ‡æ±‡æ€»ï¼š")
print(result_df.round(4))

# 2. è®¡ç®—å†²å‡»æœŸAUCä¸‹é™å¹…åº¦ï¼ˆæ ¸å¿ƒå¯¹æ¯”ï¼‰
drop_analysis = []
for model in ['LR', 'XGB']:
    for feat in ['æœªèåˆå®è§‚', 'èåˆå®è§‚(å«UnRate)']:
        # æå–æ­£å¸¸æœŸå’Œå†²å‡»æœŸçš„AUC
        normal_auc = result_df[
            (result_df['åœºæ™¯'] == 'æ­£å¸¸æœŸ') & 
            (result_df['æ¨¡å‹ç±»å‹'] == model) & 
            (result_df['ç‰¹å¾ç»„åˆ'] == feat)
        ]['AUC'].values[0]
        shock_auc = result_df[
            (result_df['åœºæ™¯'] == 'å†²å‡»æœŸ') & 
            (result_df['æ¨¡å‹ç±»å‹'] == model) & 
            (result_df['ç‰¹å¾ç»„åˆ'] == feat)
        ]['AUC'].values[0]
        # è®¡ç®—ä¸‹é™å¹…åº¦ï¼ˆ%ï¼‰
        auc_drop = round((normal_auc - shock_auc) / normal_auc * 100, 2)
        drop_analysis.append({
            'æ¨¡å‹ç±»å‹': model,
            'ç‰¹å¾ç»„åˆ': feat,
            'æ­£å¸¸æœŸAUC': normal_auc,
            'å†²å‡»æœŸAUC': shock_auc,
            'AUCä¸‹é™å¹…åº¦(%)': auc_drop
        })
drop_df = pd.DataFrame(drop_analysis)
print("\nğŸ“Š å†²å‡»æœŸAUCä¸‹é™å¹…åº¦åˆ†æï¼ˆæ ¸å¿ƒç»“è®ºä¾æ®ï¼‰ï¼š")
print(drop_df.round(4))
